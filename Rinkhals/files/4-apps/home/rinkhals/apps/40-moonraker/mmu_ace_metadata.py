import argparse
import filecmp
import json
import ast
import logging
import os
import re
import sys
import time
import traceback
import tempfile
import shutil
from typing import Dict, Any, List, Type

# -------------------------------------------------------------------------
# Metadata Extraction Logic
# -------------------------------------------------------------------------

AUTHORZIED_SLICERS = ['PrusaSlicer', 'SuperSlicer', 'OrcaSlicer', 'BambuStudio', 'AnycubicSlicerNext']

MMU_ACE_FINGERPRINT = "; processed by MmuAcePatcher"
MMU_REGEX = r"^" + MMU_ACE_FINGERPRINT
SLICER_REGEX = r"^;.*generated by ([a-z]*) .*$|^; (BambuStudio) .*$"

TOOL_DISCOVERY_REGEX = r"((^MMU_CHANGE_TOOL(_STANDALONE)? .*?TOOL=)|(^T))(?P<tool>\d{1,2})"

def gcode_processed_already(file_path):
    """Expects first line of gcode to be the FINGERPRINT"""
    mmu_regex = re.compile(MMU_REGEX, re.IGNORECASE)
    with open(file_path, 'r') as in_file:
        line = in_file.readline()
        return mmu_regex.match(line)

def parse_gcode_file(file_path):
    slicer_regex = re.compile(SLICER_REGEX, re.IGNORECASE)
    slicer = None

    tools_used = set()
    total_toolchanges = 0

    with open(file_path, 'r') as in_file:
        for line in in_file:
            # Discover slicer
            if not slicer and line.startswith(";"):
                match = slicer_regex.match(line)
                if match:
                    slicer = match.group(1) or match.group(2)
    
    if slicer in AUTHORZIED_SLICERS:
        tools_regex = re.compile(TOOL_DISCOVERY_REGEX, re.IGNORECASE)

        with open(file_path, 'r') as in_file:
            for line in in_file:
                match = tools_regex.match(line)
                if match:
                    tool = match.group("tool")
                    tools_used.add(int(tool))
                    total_toolchanges += 1

    return {
        "slicer": slicer,
        "tools_used": sorted(tools_used),
        "total_toolchanges": total_toolchanges,
    }

def process_file(input_filename, output_filename, tools_used, total_toolchanges):
    with open(input_filename, 'r') as infile, open(output_filename, 'w') as outfile:
        outfile.write(f'{MMU_ACE_FINGERPRINT}\n')
        for line in infile:
            outfile.write(line)
        # Append referenced tools metadata
        outfile.write("; referenced_tools = %s\n" % ",".join(map(str, tools_used)))

def main(config: Dict[str, Any], metadata) -> None:
    logging.debug("main setup_anycubic_slicer metadata extraction")

    path = config["gcode_dir"]
    filename = config["filename"]

    file_path = os.path.join(path, filename)
    if not os.path.isfile(file_path):
        metadata.logger.info(f"File Not Found: {file_path}")
        sys.exit(-1)

    try:
        metadata.logger.info(f"mmu_server: Pre-processing file: {file_path}")
        fname = os.path.basename(file_path)
        if fname.endswith(".gcode") and not gcode_processed_already(file_path):
            with tempfile.TemporaryDirectory() as tmp_dir_name:
                tmp_file = os.path.join(tmp_dir_name, fname)

                start = time.time()
                parse_result = parse_gcode_file(file_path)
                slicer = parse_result["slicer"]
                tools_used = parse_result["tools_used"]
                total_toolchanges = parse_result["total_toolchanges"]
                metadata.logger.info("Reading placeholders took %.2fs. Detected gcode by slicer: %s" % (time.time() - start, slicer))
                metadata.logger.info("Detected tools: %s" % tools_used)

                if tools_used is not None and len(tools_used) > 0:
                    process_file(file_path, tmp_file, tools_used, total_toolchanges)

                    # Move temporary file back in place
                    if os.path.islink(file_path):
                        file_path = os.path.realpath(file_path)
                    if not filecmp.cmp(tmp_file, file_path):
                        shutil.move(tmp_file, file_path)
                    else:
                        metadata.logger.info(f"Files are the same, skipping replacement of: {file_path} by {tmp_file}")

    except Exception:
        metadata.logger.info(traceback.format_exc())
        sys.exit(-1)

    class AnycubicSlicerNext(metadata.PrusaSlicer):
        def check_identity(self, data: str) -> bool:
            logging.debug("AnycubicSlicerNext checking identity")
            aliases = {
                'AnycubicSlicerNext': r"AnycubicSlicerNext\s(.*)\son",
            }
            for name, expr in aliases.items():
                match = re.search(expr, data)
                if match:
                    self.slicer_name = name
                    self.slicer_version = match.group(1)
                    logging.debug(f"AnycubicSlicerNext found {name} version {self.slicer_version}")
                    return True
            return False

    # Add AnycubicSlicerNext to supported slicers
    supported_slicers: List[Type[metadata.BaseSlicer]] = metadata.SUPPORTED_SLICERS
    supported_slicers.append(AnycubicSlicerNext)
    metadata.SUPPORTED_SLICERS = supported_slicers

    return metadata.main(config)


if __name__ == "__main__":
    # Make it look like we are running in the file_manager directory
    # This is required so we can import 'metadata' from the parent package
    directory = os.path.dirname(os.path.abspath(__file__))
    target_dir = os.path.join(directory, "file_manager")
    
    # Verify the path exists to avoid confusing errors
    if not os.path.exists(target_dir):
        # Fallback: if running from source root, adjust path
        target_dir = os.path.join(directory, "..", "file_manager")
        
    os.chdir(target_dir)
    sys.path.insert(0, target_dir)

    import metadata
    logger = metadata.logger
    metadata.logger.info("mmu_server: Running MMU enhanced version of metadata")

    parser = argparse.ArgumentParser(description="GCode Metadata Extraction Utility")
    parser.add_argument("-c", "--config", metavar='<config_file>', default=None, help="Optional json configuration file")
    parser.add_argument("-f", "--filename", metavar='<filename>', default=None, help="name gcode file to parse")
    parser.add_argument("-p", "--path", metavar='<path>', default=None, help="optional path to folder containing the file")
    parser.add_argument("-u", "--ufp", metavar="<ufp file>", default=None, help="optional path of ufp file to extract")
    parser.add_argument("-o", "--check-objects", dest='check_objects', action='store_true', help="process gcode file for exclude object functionality")
    
    args = parser.parse_args()
    config: Dict[str, Any] = {}
    
    if args.config is None:
        if args.filename is None:
            logger.info("The '--filename' (-f) option must be specified when --config is not set")
            sys.exit(-1)
        config["filename"] = args.filename
        config["gcode_dir"] = args.path
        config["ufp_path"] = args.ufp
        config["check_objects"] = args.check_objects
    else:
        try:
            with open(args.config, "r") as f:
                config = (json.load(f))
        except Exception:
            logger.info(traceback.format_exc())
            sys.exit(-1)
        if config.get("filename") is None:
            logger.info("The 'filename' field must be present in the configuration")
            sys.exit(-1)
            
    if config.get("gcode_dir") is None:
        # Default to current directory if not specified
        config["gcode_dir"] = os.path.abspath(os.path.dirname(__file__))

    main(config, metadata)